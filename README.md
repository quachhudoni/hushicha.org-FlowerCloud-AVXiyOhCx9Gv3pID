[合集 - 技术札纪——有限硬件与无限计算的权衡艺术(41)](https://github.com)

[1.书本介绍：技术札纪——有限硬件与无限计算的权衡艺术07-24](https://github.com/poemyang/p/19002322)[2.书本大纲：从芯片、分布式到云计算AI时代07-25](https://github.com/poemyang/p/19004265)[3.我的代码背叛了我？为什么 a=1, b=2，最后x和y都等于0？07-25](https://github.com/poemyang/p/19004704)[4.我的代码出现幻觉？说好的a = 1； x = b，怎么成了x = b； a = 1？07-28](https://github.com/poemyang/p/19008983)[5.为什么i++不是原子操作？一个让无数并发程序崩溃的“常识”07-29](https://github.com/poemyang/p/19010948)[6.没有Happens-Before？你的多线程代码就是‘一锅粥’！07-30](https://github.com/poemyang/p/19012883)[7.Hello World背后藏着什么秘密？一行代码看懂Java的“跨平台”魔法07-31](https://github.com/poemyang/p/19014740)[8.a+b=c，处理器一步搞定，Java虚拟机为啥要四步？08-01](https://github.com/poemyang/p/19016482)[9.“同声传译”还是“全文翻译”？为何HotSpot虚拟机仍要保留解释器？08-04](https://github.com/poemyang/p/19020937)[10.“代码跑着跑着，就变快了？”——揭秘Java性能幕后引擎：即时编译器08-05](https://github.com/poemyang/p/19022518)[11.Java编译器优化秘籍：字节码背后的IR魔法与常见技巧08-06](https://github.com/poemyang/p/19024509)[12.解锁硬件潜能：Java向量化计算，性能飙升W倍！08-07](https://github.com/poemyang/p/19026352)[13.new出来的对象，不一定在堆上？聊聊Java虚拟机的优化技术：逃逸分析08-08](https://github.com/poemyang/p/19027777)[14.性能优化之母：为什么说“方法内联”是编译器优化中最关键的一步棋？08-11](https://github.com/poemyang/p/19031406)[15.从纳秒到毫秒的“时空之旅”：CPU是如何看待内存与硬盘的？08-12](https://github.com/poemyang/p/19033086)[16.硬盘性能提升100倍的秘密：看懂顺序I/O的魔力08-14](https://github.com/poemyang/p/19038725)[17.十年大厂员工终明白：MySQL性能优化的尽头，是对B+树的极致理解08-18](https://github.com/poemyang/p/19043960)[18.Facebook内部都在用的存储引擎，LSM凭什么能硬扛亿级写入流量？08-21](https://github.com/poemyang/p/19050442)[19.千亿消息“过眼云烟”？Kafka把硬盘当内存用的性能魔法，全靠这一手！08-22](https://github.com/poemyang/p/19052513)[20.RPC的三大问题：跨语言、跨平台通信的终极解决方案是如何炼成的？08-27](https://github.com/poemyang/p/19060527):[milou加速器](https://xinminxuehui.org)[21.从文本到二进制：HTTP/2不止于性能，更是对HTTP/1核心语义的传承与革新08-28](https://github.com/poemyang/p/19061836)[22.从HPACK到多路复用，揭秘HTTP/2如何终结网络拥堵08-29](https://github.com/poemyang/p/19063734)[23.站在巨人的肩膀上：gRPC通过HTTP/2构建云原生时代的通信标准09-01](https://github.com/poemyang/p/19068100)[24.gRPC不是银弹：为内网极致性能，如何设计自己的RPC协议？09-03](https://github.com/poemyang/p/19071487)[25.从JSON到Protobuf，深入序列化方案的选型与原理09-04](https://github.com/poemyang/p/19073206)[26.“卧槽，系统又崩了！”——别慌，这也许是你看过最通俗易懂的分布式入门09-05](https://github.com/poemyang/p/19074847)[27.海量数据如何“安家”？一文读懂哈希、范围和一致性哈希三大分片策略09-08](https://github.com/poemyang/p/19079520)[28.“你还活着吗？” “我没死，只是网卡了！”——来自分布式世界的“生死契约”09-09](https://github.com/poemyang/p/19082361)[29.“凭什么说你比我先？”——没有上帝时钟，如何判断“谁先谁后”？09-12](https://github.com/poemyang/p/19087563)[30.“鸡蛋不能放一个篮子里”，如何确保千亿数据万无一失？09-15](https://github.com/poemyang/p/19092154)[31.系统里数据又“打架”了？让“少数服从多数”来终结这场混乱！09-18](https://github.com/poemyang/p/19097975)[32.技术圈的“绯闻女孩”：Gossip是如何把八卦秘密传遍全网的？09-19](https://github.com/poemyang/p/19100196)[33.绯闻女孩不只会八卦：从“验明正身”到“抓内鬼”，Gossip的进阶玩法09-20](https://github.com/poemyang/p/19101931)[34.从混沌到秩序：Java共享内存模型如何通过显式约束驯服并发？09-23](https://github.com/poemyang/p/19106679)[35.一把锁的两种承诺：synchronized如何同时保证互斥与内存可见性？09-24](https://github.com/poemyang/p/19108676)[36.从MESA模型到锁升级：synchronized性能逆袭的底层逻辑09-25](https://github.com/poemyang/p/19110705)[37.揭秘JUC：volatile与CAS，并发编程的两大基石09-27](https://github.com/poemyang/p/19114881)[38.“不要通过共享内存来通信”——深入理解Golang并发模型与CSP理论10-13](https://github.com/poemyang/p/19139419)[39.Goroutine间的“灵魂管道”：Channel如何实现数据同步与因果传递？10-14](https://github.com/poemyang/p/19142146)[40.“一切皆文件”：揭秘LINUX I/O与虚拟内存的底层设计哲学10-15](https://github.com/poemyang/p/19143895)

41.你的程序为何卡顿？从LINUX I/O三大模式寻找答案10-16

收起

**I/O交互流程**
在LINUX中，内核空间和用户空间都位于虚拟内存中。LINUX采用两级保护机制：0级供内核使用，3级供用户程序使用。每个进程都有独立的用户空间（0~3G），对其他进程不可见，而最高的1G虚拟内核空间则由所有进程和内核共享。
操作系统和驱动程序运行在内核空间，应用程序运行在用户空间。由于LINUX使用虚拟内存机制，两者之间不能直接通过指针传递数据。用户空间必须通过系统调用请求内核协助完成I/O操作。内核会为每个I/O设备维护缓冲区，而用户空间的数据可能被换出，因此内核无法直接使用用户空间的指针。
对于一个输入操作，进程发起I/O系统调用后，内核会先检查缓冲区是否有缓存数据。如果没有，则从设备读取数据；如果有，则直接将数据复制到用户空间。因此，网络输入操作通常分为两个阶段：
1）内核空间阶段：内核通过协议栈和设备驱动程序接收数据，并将其存储在内核缓冲区；
2）用户空间阶段：数据从内核缓冲区复制到用户进程的缓冲区后，用户进程即可处理这些数据。

![image](https://img2024.cnblogs.com/blog/757914/202510/757914-20251016212244289-2131033900.png)

**I/O操作方式**
在操作系统中，通常有三种主要的I/O操作方式，每种方式都有其独特的特性和适用场景。

**阻塞I/O**
阻塞I/O（Blocking I/O）是最简单的I/O模型。当进程发起I/O操作（如read或write）时，当前线程会被阻塞，直到I/O操作完成。这种模型是标准的同步I/O实现，例如POSIX标准中的默认read和write系统调用。
阻塞I/O的优点是实现简单，适合低并发的场景，因为内核已经对这些系统调用进行了高度优化。然而，在并发场景下，阻塞I/O的性能瓶颈会显现出来：每个I/O操作都会阻塞一个线程，导致内核需要频繁地进行线程切换，这会增加上下文切换的开销，降低处理器缓存的利用率，并可能使依赖线程本地存储（Thread-Local Storage, TLS）的代码性能下降。

![image](https://img2024.cnblogs.com/blog/757914/202510/757914-20251016212252172-427948495.png)

```
// 伪代码: 阻塞I/O
socket = accept(); // 阻塞，直到新连接到达
data = read(socket); // 阻塞，直到数据被读取
process(data);
```

**非阻塞I/O**
非阻塞I/O（Non-Blocking I/O）允许I/O操作在没有数据可用时立即返回，而不会阻塞执行线程。在非阻塞I/O模式下，如果数据未准备好，系统通常会返回一个错误码（如EAGAIN 或 EWOULDBLOCK），指示操作需要稍后重试。进程可以通过轮询监控多个文件描述符的就绪状态。
非阻塞I/O的优点是提高程序的并发性，因为它允许线程在等待I/O操作完成的同时，执行其他任务。然而，这种模式也带来了更高的编程复杂度，程序需要不断检查文件描述符的状态，以确保在数据可用时及时处理。这种轮询机制不仅增加了代码的复杂性，还可能导致处理器资源的浪费。

![image]()

以下伪代码，展示了非阻塞I/O的执行过程。

```
// 伪代码: 非阻塞I/O
while (true) {
    data = read(socket);
    if (data != EAGAIN) {
        process(data);
        break;
    }
    // do other things...
}
```

**异步 I/O**
异步I/O （Asynchronous I/O）是一种真正的异步模型，进程在发起 I/O 操作后立即返回，并通过回调函数或事件通知机制在操作完成后得到通知。典型的实现包括Windows的OVERLAPPED和I/O完成端口（IOCP），以及LINUX的原生异步I/O（AIO）。需要注意的是，LINUX的原生AIO 仅对文件I/O有效，对网络I/O的支持有限。
异步I/O的优点是能够最大限度地提高并发性能，同时减少线程阻塞和上下文切换的开销。然而，异步I/O的实现和调试复杂度较高，且在某些平台上的支持不够完善。

![image]()

```
// 伪代码: 异步I/O
// 定义一个I/O操作完成后的回调函数
void on_read_complete(data, error) {
    if (error) {
        handle_error(error);
    } else {
        process(data);
    }
    // 可以在回调中发起下一次异步读
    aio_read(socket, buffer, on_read_complete);
}

// 1. 主程序发起异步读操作，并注册回调函数
// aio_read会立即返回，不会阻塞
aio_read(socket1, buffer1, on_read_complete);
aio_read(socket2, buffer2, on_read_complete);

// 2. 主线程可以继续执行其他任务，或进入一个等待退出的循环
do_other_work();
event_loop_wait_for_shutdown(); // 例如，等待信号
```

**未完待续**

**很高兴与你相遇！如果你喜欢本文内容，记得关注哦**
